# Supervised Learning - Decision Trees

This repository contains materials related to supervised learning with decision trees. The tasks cover various aspects of decision trees for classification and regression problems, including concepts like overfitting, underfitting, pruning, and model evaluation.

## Task Overview

1. **Introduction to Decision Trees:** 
   - Explanation of how decision trees work and their intuitive decision-making process.
   
2. **Classification Trees:**
   - Overview of decision trees for datasets with categorical dependent variables.
   
3. **Regression Trees:**
   - Explanation of using decision trees for problems with numerical dependent variables.
   
4. **Overfitting and Underfitting:**
   - Discussion on the concepts of overfitting and underfitting in decision trees.
   
5. **Pruning and Tree Size Control:**
   - Techniques for pruning decision trees to prevent overfitting and controlling tree complexity.
   
6. **Development Data and Model Tuning:**
   - Importance of creating development sets for model evaluation and tuning.
   
7. **Practical Task Implementation:**
   - Instructions for creating a decision tree model to predict survival on the Titanic dataset.

## Files Included

- `Decision_Trees.ipynb`: Jupyter Notebook containing code for implementing decision trees.
- `titanic.csv`: Dataset used for the practical task on predicting Titanic passenger survival.

## Instructions

1. Clone the repository to your local machine.
2. Open and run the `Decision_Trees.ipynb` Jupyter Notebook to follow along with the tasks.
3. Complete the practical task by following the step-by-step instructions provided in the notebook.
4. Experiment with different values of `max_depth` and observe the model's accuracy on the development set.
5. Report the final model accuracy on the test data and analyze the results.

